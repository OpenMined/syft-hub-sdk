{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SyftBox SDK Development Testing\n",
    "\n",
    "This notebook is for testing and validating the SyftBox SDK during development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output --no-stderr\n",
    "\n",
    "# Install async module\n",
    "!uv pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SDK\n",
    "import syft_nsai_sdk as sdk\n",
    "import nest_asyncio\n",
    "import httpx\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import client\n",
    "from syft_nsai_sdk import Client\n",
    "from syft_nsai_sdk.utils.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-04 12:12:29 - syft_nsai_sdk - SUCCESS - Logger initialized successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# define utilities\n",
    "nest_asyncio.apply()\n",
    "logger = get_logger()\n",
    "logging.getLogger('syft_nsai_sdk').setLevel(logging.INFO)\n",
    "logger.success(\"Logger initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-09-04 12:12:30 - syft_nsai_sdk.main - INFO - Found existing accounting credentials for callis@openmined.org\u001b[0m\n",
      "\u001b[34m2025-09-04 12:12:30 - syft_nsai_sdk.main - INFO - Client initialized for callis@openmined.org\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize client\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Response received                                                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# inline service usage - , \"bob@example.com/wiki\"\n",
    "inline_result = client.pipeline(\n",
    "    data_sources=[\"callis@openmined.org/sota-free\", \"callis@openmined.org/carl-model\"], \n",
    "    synthesizer=\"callis@openmined.org/sota-free\"\n",
    ").run(messages=[{\"role\": \"user\", \"content\": \"What is Python?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-09-04 11:57:27 - syft_nsai_sdk - INFO - Pipeline result:\n",
      "\n",
      " Snippet 1. Code Interpretation Extension can generate and run Python code:\n",
      "\n",
      "The Snippet describes how the Extension can interpret and run Python code. The selection and invocation of the Extension is guided by the use of Example, which are defined as part of the Extension configuration.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# show response\n",
    "logger.info(f\"Pipeline result:\\n\\n {inline_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Response received                                                             \n",
      "\n",
      "✓ Response received                                                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Object-Oriented service usage\n",
    "pipeline = client.create_pipeline()\n",
    "pipeline.add_source(\"callis@openmined.org/sota-free\", topK=8)\n",
    "pipeline.add_source(\"callis@openmined.org/carl-model\", topK=8)\n",
    "pipeline.set_synthesizer(\"callis@openmined.org/sota-free\", temperature=0.7)  \n",
    "oop_result = pipeline.run(messages=[{\"role\": \"user\", \"content\": \"What is Python?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-09-04 12:01:38 - syft_nsai_sdk - INFO - Pipeline result:\n",
      "\n",
      " An agent is a self-directed artificial intelligence (AI) program capable of reasoning, logic, and accessing external information. This concept is based on the integration of different tools that include user interfaces, evaluation frameworks, and continuous improvement mechanisms. The software architecture also offers a set of development tools that allow developers to focus on building and refining their agents while managing the complexities of infrastructure, deployment, and maintenance. An example of this is Vertex AI platform, which simplifies the process of defining crucial elements like goals, task instructions, tools, sub-agents for task delegation, and examples - allowing developers to focus on building and refining their agents while managing the complexities of infrastructure, deployment, and maintenance.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# show response\n",
    "logger.info(f\"Pipeline result:\\n\\n {oop_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some services as objects first\n",
    "carl_model = client.load(\"callis@openmined.org/carl-model\") # paid\n",
    "sota_free = client.load(\"callis@openmined.org/sota-free\") # free\n",
    "carl_free = client.load(\"callis@openmined.org/carl-free\") # free\n",
    "carl_claude = client.load(\"callis@openmined.org/carl-claude\") # free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Response received                                                             \n",
      "\n",
      "✓ Response received                                                             \n",
      "\n",
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025-09-04 13:13:25 - syft_nsai_sdk.core.pipeline - ERROR - Search failed for callis@openmined.org/sota-free: RPC_ERROR: Polling timed out after 30/30 attempts\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Response received\n",
      "\n",
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025-09-04 13:13:26 - syft_nsai_sdk.core.pipeline - ERROR - Search failed for callis@openmined.org/sota-free: RPC_ERROR: Polling timed out after 30/30 attempts\u001b[0m\n",
      "\u001b[33m2025-09-04 13:13:26 - syft_nsai_sdk.core.pipeline - WARNING - Search failed for source callis@openmined.org/sota-free: RPC_ERROR: Polling timed out after 30/30 attempts\u001b[0m\n",
      "\u001b[33m2025-09-04 13:13:26 - syft_nsai_sdk.core.pipeline - WARNING - Search failed for source callis@openmined.org/sota-free: RPC_ERROR: Polling timed out after 30/30 attempts\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Response received\n",
      "\n",
      "✓ Response received                                                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demo mixed input types\n",
    "mixed_result = client.pipeline_mixed(\n",
    "    data_sources=[\n",
    "        \"callis@openmined.org/sota-free\",           # String\n",
    "        carl_free,                                       # Service object\n",
    "        {\"name\": \"callis@openmined.org/carl-claude\", \"topK\": 5},  # Dict with string\n",
    "        {\"name\": sota_free, \"topK\": 8}                   # Dict with Service object\n",
    "    ],\n",
    "    synthesizer=docs  # Service object as synthesizer\n",
    ").run(messages=[{\"role\": \"user\", \"content\": \"What is Python?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-09-04 12:14:53 - syft_nsai_sdk - INFO - Mixed pipeline result:\n",
      "\n",
      " An agent is a self-directed program or system that can plan and execute tasks in a specific context. It includes reasoning, logic, access to external information, and ability to plan and execute tasks beyond the capabilities of a single AI model. In this context, an example is a vertix ai platform that provides developers with a set of tools for building and refining their agents while managing complexities of infrastructure, deployment, and maintenance by itself. The whitepaper dives into all these aspects in more detail, including the sample architecture of an agent that generates code from a given query.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Mixed pipeline result:\\n\\n {mixed_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025-09-04 12:17:03 - syft_nsai_sdk.core.pipeline - ERROR - Search failed for callis@openmined.org/carl-model: RPC_ERROR: Polling timed out after 30/30 attempts\u001b[0m\n",
      "\u001b[33m2025-09-04 12:17:03 - syft_nsai_sdk.core.pipeline - WARNING - Search failed for source callis@openmined.org/carl-model: RPC_ERROR: Polling timed out after 30/30 attempts\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Response received\n",
      "\n",
      "✓ Response received                                                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demo with pure Service objects\n",
    "service_result = client.pipeline_mixed(\n",
    "    data_sources=[sota_free, carl_free],\n",
    "    synthesizer=sota_free\n",
    ").run(messages=[{\"role\": \"user\", \"content\": \"What is machine learning?\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-09-04 12:17:30 - syft_nsai_sdk - INFO - Service objects pipeline result:\n",
      "\n",
      " Machine learning (ML) is a type of AI that uses algorithms to learn from and improve upon data without being explicitly programmed. In ML, data is used to train models that can make predictions or recommendations based on their knowledge of the data. This process is often automated, meaning algorithms can continuously analyze new data and improve their predictions over time. \n",
      "\n",
      "In general, ML can be broken down into three main components: training data, model, and algorithm. The training data (also known as the \"training set\") contains the original data used to train the model. This data is typically labeled or tagged with relevant information such as categories or attributes. Once the training set is complete, the model can be created by using algorithms that fit the training data.\n",
      "\n",
      "During the modeling phase, algorithms will use a variety of techniques to analyze the data and develop predictions based on their knowledge. These predictions may be used to make decisions, recommendations, or other types of predictions in real-time or as predicted outcomes. The final output is called a \"model,\" which can be used for predictive analysis or decision-making purposes.\n",
      "\n",
      "Another important aspect of ML is the optimization process. This involves iterating through various models and selecting the best one based on performance metrics such as accuracy, error rate, or likelihood of prediction success. The final model is typically selected based on its ability to provide the most relevant insights for specific use cases or problems at hand.\n",
      "\n",
      "In summary, ML involves the training, optimization, and application of algorithms that can learn from data and provide predictions or recommendations based on their knowledge.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Service objects pipeline result:\\n\\n {service_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025-09-04 12:19:40 - syft_nsai_sdk.core.pipeline - ERROR - Search failed for callis@openmined.org/carl-model: RPC_ERROR: Polling timed out after 30/30 attempts\u001b[0m\n",
      "\u001b[33m2025-09-04 12:19:40 - syft_nsai_sdk.core.pipeline - WARNING - Search failed for source callis@openmined.org/carl-model: RPC_ERROR: Polling timed out after 30/30 attempts\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Response received\n",
      "\n",
      "✓ Response received                                                             \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Demo Service objects with different parameters\n",
    "param_result = client.pipeline_mixed(\n",
    "    data_sources=[\n",
    "        {\"name\": sota_free, \"topK\": 10},\n",
    "        {\"name\": \"callis@openmined.org/carl-claude\", \"topK\": 3}\n",
    "    ],\n",
    "    synthesizer={\"name\": sota_free, \"temperature\": 0.9}\n",
    ").run(messages=[{\"role\": \"user\", \"content\": \"Explain neural networks\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m2025-09-04 12:20:34 - syft_nsai_sdk - INFO - Parameters pipeline result:\n",
      "\n",
      " Newwhitepaper_Agent2.pdf\n",
      "The goal of an agent in AI is not just to act as a \"human\" in the context of explainable artificial intelligence (XAI) models, but also to have a clear understanding and reasoning about the inner working of such models. An agent's cognitive architecture, or how it operates, consists of three essential components: combinational reasoning, logic, and access to external information. These components help agents process information, make decisions, and take actions.\n",
      "\n",
      "In this whitepaper, we will introduce these components and the different types of agents that Generative AI models can build at the time of publication. In order to understand the inner working of an agent, let's first introduce the foundational components that drive the agent's behavior, actions, and decision-making.\n",
      "\n",
      "Combinational Reasoning: This is combination of reasoning, logic, and access to external information that are all connected to a Generative AI model invoke to support understanding the inner working of such models. Xie, M., (2022) suggests that in-context learning work, which involves observing the world and acting upon it using the tools that they have at their disposal.\n",
      "\n",
      "Scavenge Nearest Neighbors: This is a framework for understaning the differences from traditional supervised learning. Xie, M., (2022) presents this approach as a simple calculation with decision-making algorithms or implementing other probabilistic reasoning techniques. In the cognitive architecture of an agent, these components can be described as a Cognitive Architecture, and there are many such architectures that can be achieved by mixing and matching these components.\n",
      "\n",
      "Agent Orchestration Layers: This is a set of machine learning algorithms that work together to provide an intuitive user experience. In this whitepaper, we will discuss the specific implementation of each layer in the cognitive architecture section. Imagine a chef has received a specific prompt and a few key ingredients from a customer. The chef would need to figure out how to prepare the dishe or dish 'on the fly' that most closely matches the customer's original query.\n",
      "\n",
      "Fine-Tuning Based Learning: This is an example of this by retrieving information from external memory. An example of this in XAI models could be the 'Example Store' in Vertex AI extensions, or the data stores RAG based architecture mentioned previously. In general, Fine-Tuining-Based learning allows agents to learn and apply new tools before receiving any user queries.\n",
      "\n",
      "Cognitive Architecture: This is a comprehensive framework that helps agents understand and react to their environment. Xie, M., (2022) suggests that fine-tuining based learning is one of the essential components in this cognitive architecture. The goal is for agents to have access to additional tools before receiving any user queries, making it easier for them to apply specific knowledge.\n",
      "\n",
      "The model:\n",
      "In XAI models, the model refers to the langua and populates the model prompt with relevant information, tools, and associated examples by retrieving them from external memory. This helps the model understan how to apply certain tools prior to receiving any user queries.\n",
      "\n",
      "The model, however, is not a complete picture of an agent. Agents also use tools for reasoning, logic, and access to external information. For instance, in Figure 2, the model used a tool (Flights) to search for real-time external information based on the user's original query.\n",
      "\n",
      "In XAI models, the agent uses logic to make decisions based on its understanding of the inner working of the model and the tools it has at its disposal. Logic can help agents process information, make decisions, and take actions based on their knowledge. An example of this in Figure 2 is the use of combinational reasoning to provide intuitive user experiences.\n",
      "\n",
      "Conclusion:\n",
      "An agent's cognitive architecture, or how it operates, consists of three essential components: combinational reasoning, logic, and access to external information. Xie suggests that fine-tuining based learning is one of the essential components in this cognitive architecture. The goal is for agents to have access to additional tools before receiving any user queries, making it easier for them to apply specific knowledge. In XAI models, this combination of reasoning, logic, and access to external information helps agents to make decisions while providing intuitive user experiences.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Parameters pipeline result:\\n\\n {param_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
